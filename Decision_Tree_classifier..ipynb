{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHVwHYNepkXo4XGAuxKUnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhakrishna1435/ML_23AG1A66E4/blob/main/Decision_Tree_classifier..ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction to Decision Tree Classifier**\n",
        "\n",
        "A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. It's one of the most intuitive and easy-to-understand models.\n",
        "\n",
        "Think of it like a flowchart or a game of \"20 Questions.\" The tree starts with a single root node representing the entire dataset. It then splits the data into smaller, more homogeneous groups based on a series of questions about the features. Each question corresponds to an internal node, and the possible answers are the branches. The process continues until it reaches the leaf nodes, which represent the final classification or prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "cKoK9Q3bWX14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym-trK97VRGo",
        "outputId": "cc0f27c4-c1d3-4b3e-e98c-fccd2c3730be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of default Decision Tree: 0.9444\n"
          ]
        }
      ],
      "source": [
        "mport pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "wine = load_wine()\n",
        "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "y = pd.Series(wine.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "dt_default = DecisionTreeClassifier(random_state=42)\n",
        "dt_default.fit(X_train, y_train)\n",
        "\n",
        "y_pred_default = dt_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "print(f\"Accuracy of default Decision Tree: {accuracy_default:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**. Hyperparameter Tuning with GridSearchCV**\n",
        "\n",
        "Hyperparameter tuning is the process of finding the optimal model architecture. For a Decision Tree, key parameters to tune include:\n",
        "\n",
        "criterion: The function to measure the quality of a split ('gini' or 'entropy').\n",
        "\n",
        "max_depth: The maximum depth of the tree. Limiting this helps prevent overfitting.\n",
        "\n",
        "min_samples_split: The minimum number of samples required to split an internal node.\n",
        "\n",
        "min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
        "\n",
        "We will use GridSearchCV to test a \"grid\" of different parameter combinations and find the best one using cross-validation."
      ],
      "metadata": {
        "id": "e98zBg5amkX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Parameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "best_dt = grid_search.best_estimator_\n",
        "\n",
        "y_pred_tuned = best_dt.predict(X_test)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"\\nAccuracy of default Decision Tree: {accuracy_default:.4f}\")\n",
        "print(f\"Accuracy of tuned Decision Tree:   {accuracy_tuned:.4f} ✨\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb_0a1tsmxyh",
        "outputId": "bc54b4e6-0a9d-4da8-e89b-9c263e40866d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
            "\n",
            "Best Parameters found by GridSearchCV:\n",
            "{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "\n",
            "Accuracy of default Decision Tree: 0.9444\n",
            "Accuracy of tuned Decision Tree:   0.9444 ✨\n"
          ]
        }
      ]
    }
  ]
}